{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e82e68-05ac-4513-a5cf-c4ae5f28cddb",
   "metadata": {},
   "source": [
    "### Яушева АР\n",
    "## Применение\t семантического\t подобия\tдля\tзадач\tкатегоризации\n",
    "# Практическая работа 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f182d1-3312-4d73-85b4-e59b8ef310ba",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Ранее мы выделили только самые важные слова — существительные — и сравнили `fruits` только с ними, нам удалось улучшить результаты вычисления.\n",
    "Мы сравнивали слово `fruits` со всеми существительными, выделенными из совокупности предложений. Можно сделать шаг вперед и выяснить, насколько каждое из этих существительных семантически связано со словом `fruits`, и найти то из них, __степень подобия которого максимальна__: это может быть полезным для оценки общего подобия документа слову `fruits`.\n",
    "\n",
    "Потребуется модифицировать сценарий №3 так, чтобы он определял подобие токена `fruits` и каждого из существительных в предложении и находил то из них, которое демонстрирует наибольший уровень подобия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02e5cce-a17a-47f6-91bd-f862f91eb631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "     ---------------------------------------- 0.0/400.7 MB ? eta -:--:--\n",
      "     --------------------------------------- 3.9/400.7 MB 26.9 MB/s eta 0:00:15\n",
      "     - ------------------------------------ 13.4/400.7 MB 38.0 MB/s eta 0:00:11\n",
      "     -- ----------------------------------- 23.3/400.7 MB 41.6 MB/s eta 0:00:10\n",
      "     --- ---------------------------------- 34.1/400.7 MB 44.7 MB/s eta 0:00:09\n",
      "     --- ---------------------------------- 40.1/400.7 MB 41.0 MB/s eta 0:00:09\n",
      "     ---- --------------------------------- 49.5/400.7 MB 41.5 MB/s eta 0:00:09\n",
      "     ----- -------------------------------- 56.1/400.7 MB 40.4 MB/s eta 0:00:09\n",
      "     ----- -------------------------------- 61.3/400.7 MB 38.4 MB/s eta 0:00:09\n",
      "     ------ ------------------------------- 68.2/400.7 MB 37.9 MB/s eta 0:00:09\n",
      "     ------- ------------------------------ 77.1/400.7 MB 38.5 MB/s eta 0:00:09\n",
      "     -------- ----------------------------- 86.5/400.7 MB 39.1 MB/s eta 0:00:09\n",
      "     --------- ---------------------------- 95.2/400.7 MB 39.4 MB/s eta 0:00:08\n",
      "     --------- --------------------------- 102.5/400.7 MB 39.1 MB/s eta 0:00:08\n",
      "     ---------- -------------------------- 110.6/400.7 MB 39.0 MB/s eta 0:00:08\n",
      "     ----------- ------------------------- 119.5/400.7 MB 39.3 MB/s eta 0:00:08\n",
      "     ----------- ------------------------- 127.7/400.7 MB 39.3 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 136.8/400.7 MB 39.6 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 146.0/400.7 MB 39.9 MB/s eta 0:00:07\n",
      "     -------------- ---------------------- 156.0/400.7 MB 40.3 MB/s eta 0:00:07\n",
      "     --------------- --------------------- 165.7/400.7 MB 40.7 MB/s eta 0:00:06\n",
      "     ---------------- -------------------- 175.1/400.7 MB 40.9 MB/s eta 0:00:06\n",
      "     ----------------- ------------------- 184.3/400.7 MB 41.1 MB/s eta 0:00:06\n",
      "     ----------------- ------------------- 194.5/400.7 MB 41.4 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 203.2/400.7 MB 41.5 MB/s eta 0:00:05\n",
      "     ------------------- ----------------- 213.1/400.7 MB 41.7 MB/s eta 0:00:05\n",
      "     -------------------- ---------------- 221.8/400.7 MB 41.8 MB/s eta 0:00:05\n",
      "     --------------------- --------------- 230.9/400.7 MB 41.8 MB/s eta 0:00:05\n",
      "     ---------------------- -------------- 239.9/400.7 MB 41.9 MB/s eta 0:00:04\n",
      "     ---------------------- -------------- 247.7/400.7 MB 41.8 MB/s eta 0:00:04\n",
      "     ----------------------- ------------- 256.9/400.7 MB 41.9 MB/s eta 0:00:04\n",
      "     ------------------------ ------------ 266.6/400.7 MB 42.3 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 276.3/400.7 MB 42.5 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 285.0/400.7 MB 42.3 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 293.6/400.7 MB 42.0 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 303.0/400.7 MB 42.5 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 313.3/400.7 MB 42.6 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 321.9/400.7 MB 43.5 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 325.1/400.7 MB 43.8 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 332.9/400.7 MB 42.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 341.6/400.7 MB 42.6 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 350.7/400.7 MB 42.7 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 359.1/400.7 MB 42.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 369.1/400.7 MB 43.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 378.3/400.7 MB 43.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 387.4/400.7 MB 43.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  396.4/400.7 MB 43.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 43.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 43.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  400.6/400.7 MB 43.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 400.7/400.7 MB 38.9 MB/s  0:00:10\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e37c00d9-38b0-41a3-9f31-f0bbcb079d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Предложение 1: I want to buy this beautiful book at the end of the week.\n",
      "Наиболее подобное существительное: 'end' (схожесть: 0.2148)\n",
      "\n",
      "\n",
      "Предложение 2: Sales of citrus have increased over the last year.\n",
      "Наиболее подобное существительное: 'citrus' (схожесть: 0.6389)\n",
      "\n",
      "\n",
      "Предложение 3: How much do you know about this type of tree?\n",
      "Наиболее подобное существительное: 'tree' (схожесть: 0.4154)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "token = nlp('fruits')[0]\n",
    "\n",
    "sentences = [\n",
    "    'I want to buy this beautiful book at the end of the week.',\n",
    "    'Sales of citrus have increased over the last year.', \n",
    "    'How much do you know about this type of tree?'\n",
    "]\n",
    "\n",
    "for i, sentence_text in enumerate(sentences):\n",
    "    doc = nlp(sentence_text)\n",
    "    \n",
    "    print(f\"\\nПредложение {i+1}: {sentence_text}\")\n",
    "    \n",
    "    nouns = [tok for tok in doc if tok.pos_ == 'NOUN']\n",
    "    \n",
    "    similarities = {noun.text: token.similarity(noun) for noun in nouns}\n",
    "    \n",
    "    max_noun = max(similarities, key=similarities.get)\n",
    "    max_similarity = similarities[max_noun]\n",
    "    \n",
    "    print(f\"Наиболее подобное существительное: '{max_noun}' (схожесть: {max_similarity:.4f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f451c-f502-43cc-8878-25f85655a2d0",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Мы создали два объекта Doc — по одному для каждого примера предложения. На практике же текст обычно состоит из множества предложений,  вследствие чего создавать объект Doc для каждого предложения нерационально. Перепишите  сценарий  таким образом, чтобы создавался один общий объект Doc. Затем,  воспользуйтесь  свойством `doc.sents`,  с которым вы познакомились на  второй  лекции,  для манипуляций с обоими предложениями.\n",
    "\n",
    "Впрочем, учтите, что `doc.sents` — объект-генератор — не индексируется и,  значит,  к его элементам нельзя обращаться по индексам.  Для решения этой проблемы преобразуйте doc. sents в список:\n",
    "$$ sents = list(doc. sents) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f17272-196c-4a06-b918-8e76ead83790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ схожести со словом 'fruits'\n",
      "\n",
      "Предложение 1: \n",
      "I want to buy this beautiful book at the end of the week. \n",
      "\n",
      "Наиболее похожее существительное: 'end' (схожесть: 0.2148)\n",
      "Все схожести:\n",
      "  book: 0.1425\n",
      "  end: 0.2148\n",
      "  week: 0.1557\n",
      "\n",
      "Предложение 2: Sales of citrus have increased over the last year. \n",
      "\n",
      "Наиболее похожее существительное: 'citrus' (схожесть: 0.6389)\n",
      "Все схожести:\n",
      "  Sales: 0.1579\n",
      "  citrus: 0.6389\n",
      "  year: 0.1616\n",
      "\n",
      "Предложение 3: How much do you know about this type of tree?\n",
      "\n",
      "Наиболее похожее существительное: 'tree' (схожесть: 0.4154)\n",
      "Все схожести:\n",
      "  type: 0.2130\n",
      "  tree: 0.4154\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "text = \"\"\"\n",
    "I want to buy this beautiful book at the end of the week. \n",
    "Sales of citrus have increased over the last year. \n",
    "How much do you know about this type of tree?\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "sents = list(doc.sents)\n",
    "\n",
    "token = nlp('fruits')[0]\n",
    "\n",
    "print(\"Анализ схожести со словом 'fruits'\")\n",
    "\n",
    "for i, sent in enumerate(sents):\n",
    "    print(f\"\\nПредложение {i+1}: {sent.text}\")\n",
    "    \n",
    "    nouns = [tok for tok in sent if tok.pos_ == 'NOUN']\n",
    "\n",
    "    similarities = {noun.text: token.similarity(noun) for noun in nouns}\n",
    "    \n",
    "    max_noun = max(similarities, key=similarities.get)\n",
    "    max_similarity = similarities[max_noun]\n",
    "    \n",
    "    print(f\"Наиболее похожее существительное: '{max_noun}' (схожесть: {max_similarity:.4f})\")\n",
    "    \n",
    "    print(\"Все схожести:\")\n",
    "    for noun_text, similarity in similarities.items():\n",
    "        print(f\"  {noun_text}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d812f8-f484-493b-af4c-3452ec00ac27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
